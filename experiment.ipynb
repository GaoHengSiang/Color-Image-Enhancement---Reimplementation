{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_rgb_to_xyz(image, M, gamma_r, gamma_g, gamma_b) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Transforms an RGB image using the formula [x y z] = M [R^gamma_r G^gamma_g B^gamma_b].\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image as a 3D numpy array (H x W x 3) in RGB format.\n",
    "\n",
    "        M (numpy.ndarray): 3x3 transformation matrix. (device characteristic)\n",
    "\n",
    "        gamma_r (float): Gamma correction for the red channel. (device characteristic)\n",
    "\n",
    "        gamma_g (float): Gamma correction for the green channel. (device characteristic)\n",
    "\n",
    "        gamma_b (float): Gamma correction for the blue channel. (device characteristic)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Transformed image (H x W x 3).\n",
    "    \"\"\"\n",
    "    # Apply gamma correction to each channel\n",
    "    image_gamma = np.zeros_like(image, dtype=np.float32)\n",
    "    h ,w, _ = image.shape\n",
    "\n",
    "    # Assert all values are in the range [0, 255]\n",
    "    assert np.all(image >= 0), \"Some values are less than 0!\"\n",
    "    assert np.all(image <= 255), \"Some values are greater than 255!\"\n",
    "\n",
    "    image_gamma[..., 0] = image[..., 0] ** gamma_r  # R^gamma_r\n",
    "    image_gamma[..., 1] = image[..., 1] ** gamma_g  # G^gamma_g\n",
    "    image_gamma[..., 2] = image[..., 2] ** gamma_b  # B^gamma_b\n",
    "\n",
    "    # Apply the matrix transformation\n",
    "    transformed = np.dot(M, image_gamma.reshape(-1, 3).T).T\n",
    "\n",
    "    # Reshape back to the original image dimensions\n",
    "    return transformed.reshape(h, w, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIECAM02:\n",
    "    \"\"\"\n",
    "    Implementation of the forward CIECAM02 color appearance model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, constants: dict, matrices: dict, colordata: list):\n",
    "        \"\"\"\n",
    "        Initializes the CIECAM02 model with shared constants and matrices.\n",
    "\n",
    "        Args:\n",
    "            constants (dict): Dictionary containing configuration parameters \n",
    "                such as white points, surround parameters, light intensity, and background intensity.\n",
    "            matrices (dict): Dictionary containing precomputed matrices \n",
    "                (Mcat02, inv_Mcat02, Mhpe, inv_Mhpe, etc.).\n",
    "            color_data (list): Unique hue data for calculation of hue quadrature\n",
    "        \"\"\"\n",
    "        self.constants = constants\n",
    "        self.colordata = colordata\n",
    "        \n",
    "        self.Mcat02 = matrices[\"CAT02\"]\n",
    "        self.inv_Mcat02 = matrices[\"inv_CAT02\"] \n",
    "        self.Mhpe = matrices[\"HPE\"]\n",
    "        self.inv_Mhpe = matrices[\"inv_HPE\"]\n",
    "\n",
    "        # Initialize default configurations\n",
    "        self.current_white = self.constants[\"whitepoint\"][\"white\"]\n",
    "        self.current_env = self.constants[\"surround\"][\"average\"]\n",
    "        self.current_light = self.constants[\"light_intensity\"][\"default\"]\n",
    "        self.current_bg = self.constants[\"bg_intensity\"][\"default\"]\n",
    "\n",
    "    def configure(self, white=\"white\", surround=\"average\", light=\"default\", bg=\"default\"):\n",
    "        \"\"\"\n",
    "        Configures the model with specific environmental parameters.\n",
    "\n",
    "        Args:\n",
    "            white (str): Key for the white point to use.\n",
    "            surround (str): Key for the surround parameters to use.\n",
    "            light (str): Key for the luminance of the adapting field.\n",
    "            bg (str): Key for the background intensity.\n",
    "        \"\"\"\n",
    "        self.current_white = self.constants[\"whitepoint\"][white]\n",
    "        self.current_env = self.constants[\"surround_params\"][surround]\n",
    "        self.current_light = self.constants[\"light_intensity\"][light]\n",
    "        self.current_bg = self.constants[\"bg_intensity\"][bg]\n",
    "\n",
    "    def calculate_independent_parameters(self):\n",
    "        \"\"\"\n",
    "        Calculates input-independent parameters needed for CIECAM02 transformations.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary of independent parameters.\n",
    "        \"\"\"\n",
    "        Xw, Yw, Zw = self.current_white\n",
    "        Nc, c, F = self.current_env[\"Nc\"], self.current_env[\"c\"], self.current_env[\"F\"]\n",
    "        LA = self.current_light\n",
    "        Yb = self.current_bg\n",
    "\n",
    "        # Compute chromatic adaptation parameters\n",
    "        Rw, Gw, Bw = self.Mcat02.dot([Xw, Yw, Zw])\n",
    "        D = F * (1 - (1 / 3.6) * np.exp((-LA - 42) / 92))\n",
    "        D = np.clip(D, 0, 1)\n",
    "\n",
    "        Dr, Dg, Db = Yw * D / Rw + (1 - D), Yw * D / Gw + (1 - D), Yw * D / Bw + (1 - D)\n",
    "        Rwc, Gwc, Bwc = Dr * Rw, Dg * Gw, Db * Bw\n",
    "\n",
    "        # Compute the viewing condition parameters\n",
    "        k = 1 / (5 * LA + 1)\n",
    "        FL = 0.2 * (k**4) * (5 * LA) + 0.1 * ((1 - k**4)**2) * ((5 * LA)**(1 / 3.0))\n",
    "\n",
    "        n = Yb / Yw\n",
    "        n = np.clip(n, 0.000001, 1)\n",
    "        Nbb = Ncb = 0.725 * (1 / n)**0.2\n",
    "        z = 1.48 + n**0.5\n",
    "\n",
    "        Rw_, Gw_, Bw_ = self.Mhpe.dot(self.inv_Mcat02.dot([Rwc, Gwc, Bwc]))\n",
    "\n",
    "        # TODO: Refactor the following three lines into a function\n",
    "        Rwa_ = (400 * (FL * Rw_ / 100)**0.42) / (27.13 + (FL * Rw_ / 100)**0.42) + 0.1\n",
    "        Gwa_ = (400 * (FL * Gw_ / 100)**0.42) / (27.13 + (FL * Gw_ / 100)**0.42) + 0.1\n",
    "        Bwa_ = (400 * (FL * Bw_ / 100)**0.42) / (27.13 + (FL * Bw_ / 100)**0.42) + 0.1\n",
    "\n",
    "        Aw = Nbb * (2 * Rwa_ + Gwa_ + Bwa_ / 20 - 0.305)\n",
    "\n",
    "        return {\n",
    "            \"D\": D, \"Dr\": Dr, \"Dg\": Dg, \"Db\": Db,\n",
    "            \"FL\": FL, \"n\": n, \"Nbb\": Nbb, \"Ncb\": Ncb, \n",
    "            \"Nc\": Nc, \"F\": F, \"z\": z, \"Aw\": Aw, \"c\": c\n",
    "        }\n",
    "    \n",
    "    def transfer_hue(self, h_prime, i):\n",
    "        data_i = self.colordata[i-1]\n",
    "        h_i, e_i, H_i = data_i[0], data_i[1], data_i[2]\n",
    "        data_i1 = self.colordata[i]\n",
    "        h_i1, e_i1 = data_i1[0], data_i1[1]\n",
    "        Hue = H_i + (\n",
    "            (100 * (h_prime-h_i)/e_i) /\n",
    "            (((h_prime-h_i)/e_i) + (h_i1-h_prime)/e_i1))\n",
    "        return Hue\n",
    "    \n",
    "    def xyz_to_ciecam02(self, XYZ):\n",
    "        \"\"\"\n",
    "        Converts XYZ tristimulus values to CIECAM02 model.\n",
    "\n",
    "        Args:\n",
    "            XYZ (numpy.ndarray): Array of XYZ values.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Array of CIECAM02 attributes.\n",
    "        \"\"\"\n",
    "        params = self.calculate_independent_parameters()\n",
    "        # Dr, Dg, Db = params[\"Dr\"], params[\"Dg\"], params[\"Db\"]\n",
    "        FL, Aw, z = params[\"FL\"], params[\"Aw\"], params[\"z\"]\n",
    "        # Nbb, Ncb, n = params[\"Nbb\"], params[\"Ncb\"], params[\"n\"]\n",
    "\n",
    "        # Step 1: Chromatic adaptation\n",
    "        RGB = XYZ.dot(self.Mcat02.T)\n",
    "        # Step 2: Calculate the corresponding cone responses\n",
    "        RcGcBc = RGB * [params[\"Dr\"], params[\"Dg\"], params[\"Db\"]]\n",
    "        # Step 3: Calculate Hunt-Pointer-Estevex response\n",
    "        R_G_B_ = RcGcBc.dot(self.inv_Mcat02.T).dot(self.Mhpe.T)\n",
    "\n",
    "        # Step 4: Post-adaptation response\n",
    "        R_G_B_in = np.power(FL * R_G_B_ / 100, 0.42)\n",
    "        Ra_Ga_Ba_ = (400 * R_G_B_in) / (27.13 + R_G_B_in) + 0.1\n",
    "\n",
    "        # Step 5: Calculate redness-greeness (a), yellowness-blueness (b) components and hue angle (h)\n",
    "        a = Ra_Ga_Ba_[:, 0] - 12 * Ra_Ga_Ba_[:, 1] / 11 + Ra_Ga_Ba_[:, 2] / 11\n",
    "        b = (Ra_Ga_Ba_[:, 0] + Ra_Ga_Ba_[:, 1] - 2 * Ra_Ga_Ba_[:, 2]) / 9\n",
    "        h = np.arctan2(b, a) * (180 / np.pi)\n",
    "        h = np.where(h < 0, h + 360, h)\n",
    "\n",
    "        # Step 6: Calculate eccentricity (etemp) and hue composition (H)\n",
    "        h_prime = np.where(h < self.colordata[0][0], h+360, h)\n",
    "        etemp = (np.cos(h_prime * np.pi/180 + 2) + 3.8) * (1/4)\n",
    "        # List of values for h_prime\n",
    "        coarray = np.array([20.14, 90, 164.25, 237.53, 380.14])\n",
    "        position_ = coarray.searchsorted(h_prime)\n",
    "        ufunc_TransferHue = np.frompyfunc(self.transfer_hue, 2, 1)\n",
    "        H = ufunc_TransferHue(h_prime, position_).astype('float')   \n",
    "\n",
    "        # Step 7: Calcualte achromatic response (A) \n",
    "        A = params[\"Nbb\"] * (\n",
    "            2*Ra_Ga_Ba_[:, 0] + Ra_Ga_Ba_[:, 1] + Ra_Ga_Ba_[:, 2] / 20 - 0.305)\n",
    "        \n",
    "        # Step 8: Calcualte the correlate of lightness (J)\n",
    "        J = 100 * (A / Aw)**(params[\"c\"]*params[\"z\"])\n",
    "\n",
    "        # Step 9: Calculate the correlate of brightness (Q)\n",
    "        Q = (4 / params[\"c\"]) * ((J / 100)**0.5) * (Aw + 4)*  (FL**0.25)\n",
    "\n",
    "        # Step 10 (Optional): Calcualte the correlates of chroma (C), colourfulness (M), and saturation (s)\n",
    "        t = (\n",
    "            (50000/13.0)*params[\"Nc\"]*params[\"Ncb\"]*etemp*((a**2+b**2)**0.5)) /\\\n",
    "            (Ra_Ga_Ba_[:, 0]+Ra_Ga_Ba_[:, 1]+(21/20.0)*Ra_Ga_Ba_[:, 2])\n",
    "        C = t**0.9*((J/100.0)**0.5)*((1.64-(0.29**params[\"n\"]))**0.73)\n",
    "        M = C*(FL**0.25)\n",
    "        s = 100*((M/Q)**0.5)\n",
    "\n",
    "        # We only need to return 3 out of 7 components calculated. Here, I chose J, Q, H. The inverse will be built upon these three components. \n",
    "\n",
    "        return np.array([J, Q, H]).T*np.array([1.0, 1.0, 0.9]) # np.array([h, H, J, Q, C, M, s]).T\n",
    "    \n",
    "    def inverse_transfer_hue(self, H_, coarray):\n",
    "        position = (coarray.searchsorted(H_))\n",
    "        C1 = self.colordata[position - 1]\n",
    "        C2 = self.colordata[position]\n",
    "        h = ((H_-C1[2])*(C2[1]*C1[0]-C1[1]*C2[0])-100*C1[0]*C2[1]) /\\\n",
    "            ((H_-C1[2])*(C2[1]-C1[1]) - 100*C2[1])\n",
    "        if h > 360:\n",
    "            h -= 360\n",
    "        return h\n",
    "    \n",
    "    def inverse_model(self, JCH):\n",
    "        \"\"\"\n",
    "        Converts JCH (Lightness, Chroma, Hue) to XYZ color space using the CIECAM02 model.\n",
    "\n",
    "        Args:\n",
    "            JCH (numpy.ndarray): Array of shape (N, 3) containing J (Lightness), C (Chroma), and H (Hue in CAM02).\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Array of shape (N, 3) containing XYZ tristimulus values.\n",
    "        \"\"\"\n",
    "        # Step 1: Extract J, C, and H and handle scaling for input format\n",
    "        JCH = JCH * np.array([1.0, 1.0, 10 / 9.0])\n",
    "        J, C, H = JCH[:, 0], JCH[:, 1], JCH[:, 2]\n",
    "        # Clip J and C to avoid numerical issues\n",
    "        J = np.maximum(J, 1e-5)\n",
    "        C = np.maximum(C, 1e-5)\n",
    "\n",
    "        coarray = np.array([0.0, 100.0, 200.0, 300.0, 400.0])\n",
    "        # position_ = coarray.searchsorted(H)\n",
    "        # ufunc_TransferHue = np.frompyfunc(self.inverse_transfer_hue, 2, 1)\n",
    "        # h_deg = ufunc_TransferHue(JCH[:, 2], position_).astype('float')\n",
    "        h_deg = np.array([self.inverse_transfer_hue(H_i, coarray) for H_i in H])\n",
    "\n",
    "        # Step 2: Calculate t, A, and p1, p2, p3 based on J, C, and H\n",
    "        params = self.calculate_independent_parameters()\n",
    "        t = (C / ((J / 100.0) ** 0.5 * ((1.64 - 0.29 ** params[\"n\"]) ** 0.73))) ** (1 / 0.9)\n",
    "        t = np.maximum(t, 1e-5)\n",
    "        etemp = (np.cos(h_deg*np.pi/180 + 2) + 3.8) * (1 / 4)\n",
    "        A = params[\"Aw\"] * (J / 100) ** (1 / (params[\"c\"] * params[\"z\"]))\n",
    "        p1 = ((50000 / 13.0) * params[\"Nc\"] * params[\"Ncb\"] * etemp) / t\n",
    "        p2 = A / params[\"Nbb\"] + 0.305\n",
    "        p3 = 21 / 20.0\n",
    "        h_rad = np.radians(h_deg)\n",
    "\n",
    "        # Step 3: Compute a and b\n",
    "        # def compute_a_b(h, p1, p2):\n",
    "        #     if np.abs(np.sin(h)) >= np.abs(np.cos(h)):\n",
    "        #         p4 = p1 / np.sin(h)\n",
    "        #         b = (p2 * (2 + p3) * (460.0 / 1403)) / (\n",
    "        #             p4 + (2 + p3) * (220.0 / 1403) * (np.cos(h) / np.sin(h)) - 27.0 / 1403 + p3 * (6300.0 / 1403)\n",
    "        #         )\n",
    "        #         a = b * (np.cos(h) / np.sin(h))\n",
    "        #     else:\n",
    "        #         p5 = p1 / np.cos(h)\n",
    "        #         a = (p2 * (2 + p3) * (460.0 / 1403)) / (\n",
    "        #             p5 + (2 + p3) * (220.0 / 1403) - (27.0 / 1403 - p3 * (6300.0 / 1403)) * (np.sin(h) / np.cos(h))\n",
    "        #         )\n",
    "        #         b = a * (np.sin(h) / np.cos(h))\n",
    "        #     return a, b\n",
    "        \n",
    "        def compute_a_b(t, h, p1, p2):\n",
    "            if t == 0:\n",
    "                a, b = 0, 0\n",
    "            elif abs(np.sin(h)) >= abs(np.cos(h)):\n",
    "                p4 = p1/np.sin(h)\n",
    "                b = (p2*(2+p3)*(460.0/1403)) / (\n",
    "                        p4+(2+p3)*(220.0/1403)*(np.cos(h)/np.sin(h)) - 27.0/1403 +\n",
    "                        p3*(6300.0/1403))\n",
    "                a = b*(np.cos(h)/np.sin(h))\n",
    "            else:  # abs(np.cos(h))>abs(np.sin(h)):\n",
    "                p5 = p1/np.cos(h)\n",
    "                a = (p2*(2+p3)*(460.0/1403)) / (\n",
    "                        p5+(2+p3)*(220.0/1403) - (\n",
    "                            27.0/1403 - p3*(6300.0/1403))*(np.sin(h)/np.cos(h)))\n",
    "                b = a*(np.sin(h)/np.cos(h))\n",
    "            return np.array([a, b])\n",
    "\n",
    "        ufunc_evalAB = np.frompyfunc(compute_a_b, 4, 1)\n",
    "        ab_values = np.vstack(ufunc_evalAB(t, h_rad, p1, p2))\n",
    "        # ab_values = []\n",
    "        # for i, h in enumerate(h_rad):\n",
    "        #     if t[i] == 0:\n",
    "        #         a, b = 0, 0\n",
    "        #     else:\n",
    "        #         a, b = compute_a_b(h, p1[i], p2[i])\n",
    "        # ab_values = np.array(\n",
    "        #     [compute_a_b(t_i, h, p1[i], p2[i]) for i, t_i, h in enumerate((t,h_rad))])\n",
    "        a, b = ab_values[:, 0], ab_values[:, 1]\n",
    "\n",
    "        # Step 4: Calculate post-adaptation values Ra_, Ga_, Ba_\n",
    "        Ra_ = (460 * p2 + 451 * a + 288 * b) / 1403.0\n",
    "        Ga_ = (460 * p2 - 891 * a - 261 * b) / 1403.0\n",
    "        Ba_ = (460 * p2 - 220 * a - 6300 * b) / 1403.0\n",
    "\n",
    "        # Step 5: Convert Ra_, Ga_, Ba_ to R_, G_, B_\n",
    "        def post_adaptation_transform(value_a, FL):\n",
    "            return np.sign(value_a - 0.1) * (100.0 / FL) * ((27.13 * np.abs(value_a - 0.1)) / (400 - np.abs(value_a - 0.1))) ** (1 / 0.42)\n",
    "\n",
    "        R_ = post_adaptation_transform(Ra_, params[\"FL\"])\n",
    "        G_ = post_adaptation_transform(Ga_, params[\"FL\"])\n",
    "        B_ = post_adaptation_transform(Ba_, params[\"FL\"])\n",
    "\n",
    "        # Step 6: Calculate Rc, Gc, Bc using inverse Hunt-Pointer-Estevez matrix\n",
    "        RcGcBc = (np.array([R_, G_, B_]).T).dot(self.inv_Mhpe.T).dot(self.Mcat02.T)\n",
    "\n",
    "        # Step 7: Adjust Rc, Gc, Bc to R, G, B\n",
    "        RGB = RcGcBc / np.array([params[\"Dr\"], params[\"Dg\"], params[\"Db\"]])\n",
    "\n",
    "        # Step 8: Convert R, G, B to XYZ using inverse chromatic adaptation\n",
    "        XYZ = RGB.dot(self.inv_Mcat02.T)\n",
    "\n",
    "        return XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(original_rgb: np.ndarray, enhanced_rgb: np.ndarray):\n",
    "    \"\"\"\n",
    "    Displays the original and enhanced images.\n",
    "    \n",
    "    Args:\n",
    "        original_rgb (np.ndarray): Original image in RGB.\n",
    "        enhanced_rgb (np.ndarray): Enhanced image in RGB.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#NO NEED TO CONVERT IF IT IS ALREADY RGB\n",
    "    axes[0].imshow(original_rgb)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow((enhanced_rgb * 255).astype(np.uint8))\n",
    "    axes[1].set_title(\"Enhanced Image\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_xyz_to_rgb(image, M, gamma_r, gamma_g, gamma_b) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs the inverse operation of device_rgb_to_xyz\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image as a 3D numpy array (H x W x 3) in XYZ format.\n",
    "\n",
    "        M (numpy.ndarray): 3x3 transformation matrix. (device characteristic)\n",
    "\n",
    "        gamma_r (float): Gamma correction for the red channel. (device characteristic)\n",
    "\n",
    "        gamma_g (float): Gamma correction for the green channel. (device characteristic)\n",
    "\n",
    "        gamma_b (float): Gamma correction for the blue channel. (device characteristic)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Transformed image (H x W x 3).\n",
    "    \"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    M_inverse = np.linalg.inv(M)\n",
    "    image_inverse = np.dot(M_inverse, image.reshape(-1, 3).T).T\n",
    "    image_inverse = image_inverse.reshape(h, w, 3)\n",
    "\n",
    "\n",
    "    # Assert all values are in the range [0, inf)\n",
    "    #assert np.all(image_inverse >= 0), \"Some values are less than 0!\"\n",
    "    if np.any(image_inverse < 0):\n",
    "        print (\"clipping negative intermediate values during conversion\")\n",
    "        image_inverse = np.clip(image_inverse, a_min = 0, a_max = None)\n",
    "\n",
    "    image_inverse[..., 0] = image_inverse[..., 0] ** (1/gamma_r)  \n",
    "    image_inverse[..., 1] = image_inverse[..., 1] ** (1/gamma_g)  \n",
    "    image_inverse[..., 2] = image_inverse[..., 2] ** (1/gamma_b)\n",
    "\n",
    "    # Reshape back to the original image dimensions\n",
    "    return image_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Characteristics =================================\n",
    "#full light\n",
    "gamma_rf, gamma_gf, gamma_bf = 2.4767, 2.4286, 2.3792\n",
    "M_f = np.array([[95.57,  64.67,  33.01],\n",
    "                [49.49, 137.29,  14.76],\n",
    "                [ 0.44,  27.21, 169.83]])\n",
    "\n",
    "#low light\n",
    "gamma_rl, gamma_gl, gamma_bl = 2.2212, 2.1044, 2.1835\n",
    "M_l = np.array([[4.61, 3.35, 1.78],\n",
    "                [2.48, 7.16, 0.79],\n",
    "                [0.28, 1.93, 8.93]])\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape (H, W, C): (512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read the image \n",
    "image_bgr = cv2.imread(\"./Lenna.png\")\n",
    "\n",
    "# Convert the image from BGR to RGB if it exists. \n",
    "if image_bgr is not None:\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)  \n",
    "else:\n",
    "    raise FileNotFoundError(\"Image does not exist.\") \n",
    "\n",
    "image_shape = image_rgb.shape\n",
    "# Display the image dimensions\n",
    "print(\"Image shape (H, W, C):\", image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_xyz = device_rgb_to_xyz(\n",
    "    image=image_rgb,\n",
    "    M=M_f, \n",
    "    gamma_r=gamma_rf,\n",
    "    gamma_g=gamma_gf,\n",
    "    gamma_b=gamma_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Constant Parameters ========== #\n",
    "whitepoint = {\n",
    "    'white': [95.05, 100.00, 108.88],\n",
    "    'c': [109.85, 100.0, 35.58]}\n",
    "\n",
    "surround_params = {\n",
    "    'average': {'F': 1.0, 'c': 0.69, 'Nc': 1.0},\n",
    "    'dim': {'F': 0.9, 'c': 0.59, 'Nc': 0.95},\n",
    "    'dark': {'F': 0.8, 'c': 0.525, 'Nc': 0.8},\n",
    "}\n",
    "\n",
    "light_intensity = {'default': 80.0, 'high': 318.31, 'low': 31.83}\n",
    "bg_intensity = {'default': 16.0, 'high': 20.0, 'low': 10.0}\n",
    "# Reference white in reference illuminant\n",
    "Xwr, Ywr, Zwr = 100, 100, 100 \n",
    "\n",
    "Mcat02 = np.array([\n",
    "    [0.7328, 0.4296, -0.1624],\n",
    "    [-0.7036, 1.6975, 0.0061],\n",
    "    [0.0030, 0.0136, 0.9834]])\n",
    "inv_Mcat02 = np.array([\n",
    "    [1.096241, -0.278869, 0.182745],\n",
    "    [0.454369, 0.473533, 0.072098],\n",
    "    [-0.009628, -0.005698, 1.015326]])\n",
    "Mhpe = np.array([\n",
    "    [0.38971, 0.68898, -0.07868],\n",
    "    [-0.22981, 1.18340, 0.04641],\n",
    "    [0.00000, 0.00000, 1.00000]])\n",
    "inv_Mhpe = np.array([\n",
    "    [1.910197, -1.112124, 0.201908],\n",
    "    [0.370950, 0.629054, -0.000008],\n",
    "    [0.000000, 0.000000, 1.000000]])\n",
    "# Unique hue data for calculation of hue quadrature (Table 2.4)\n",
    "colordata = [\n",
    "    [20.14, 0.8, 0], \n",
    "    [90, 0.7, 100], \n",
    "    [164.25, 1.0, 200],\n",
    "    [237.53, 1.2, 300],\n",
    "    [380.14, 0.8, 400]]\n",
    "\n",
    "# ===== Grouping for Convenience ===== #\n",
    "constants = {\n",
    "    \"whitepoint\": whitepoint, \n",
    "    \"surround\": surround_params,\n",
    "    \"light_intensity\": light_intensity,\n",
    "    \"bg_intensity\": bg_intensity, \n",
    "    \"reference_white\": (Xwr, Ywr, Zwr)\n",
    "}\n",
    "\n",
    "matrices = {\n",
    "    \"CAT02\": Mcat02,\n",
    "    \"inv_CAT02\": inv_Mcat02, \n",
    "    \"HPE\": Mhpe, \n",
    "    \"inv_HPE\": inv_Mhpe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from parameters import constants, matrices, colordata \n",
    "\n",
    "model = CIECAM02(constants, matrices, colordata) # default configuration\n",
    "# # Configure the model according to the surrounding condition\n",
    "# model.configure(white=\"white\", surround=\"dim\", light=\"low\", bg=\"high\")\n",
    "JCH = model.xyz_to_ciecam02(image_xyz.reshape(-1, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "\n",
    "image_xyz = model.inverse_model(JCH) \n",
    "# OUTPUT IS NAN :/ \n",
    "\n",
    "# image_rgb = device_xyz_to_rgb(image_xyz, M_f, gamma_rf, gamma_gf, gamma_bf)\n",
    "# im = Image.fromarray(image_rgb)\n",
    "# im.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
